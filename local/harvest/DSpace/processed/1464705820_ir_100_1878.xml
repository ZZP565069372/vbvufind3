<oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd"><identifier>ir-100-1878</identifier><datestamp>2011-12-15T09:11:08Z</datestamp><dc:title>Development of an audio-visual database system for human identification</dc:title><dc:creator>BARGALE, CB</dc:creator><dc:creator>CHAUDHURI, S</dc:creator><dc:creator>BHATTACHARYYA, P</dc:creator><dc:subject>faces</dc:subject><dc:description>Database systems dealing with textual contents have been in use for a long time. A database management system (DBMS) allows convenient and efficient storage and retrieval of a huge amount of data. Traditional databases are designed for handling alphanumeric data efficiently, but fail to manage complex data like audio and/or video. One dimensional audio data and two dimensional image data can be stored in the form of a binary large object (BLOB) with no emphasis on the contents. Textual information can be attached to BLOBs for retrieval, but mere a textual information is insufficient for describing the rich contents of data. So there is a need to extend the capabilities of such information management system to handle both audio and visual data. Contents of such data items can be extracted in the form of features which can be used for distinction amongst the instances of these data types. This paper describes how the relational data model can be extended to retrieve face images and audio data in the form of utterances of alphabets. Face images are characterized by sizes of different objects, e.g. nose, lips and the inter-object distances. The audio data is characterized by pitch, formants and LPC coefficients. The purpose of the paper is to develop an automated system for human identification based on audio-visual querying. The system allows the query to be partly audio, partly visual and textual.</dc:description><dc:publisher>SPRINGER-VERLAG BERLIN</dc:publisher><dc:date>2011-10-23T11:54:51Z</dc:date><dc:date>2011-12-15T09:11:08Z</dc:date><dc:date>2011-10-23T11:54:51Z</dc:date><dc:date>2011-12-15T09:11:08Z</dc:date><dc:date>1997</dc:date><dc:type>Article; Proceedings Paper</dc:type><dc:identifier>AUDIO- AND VIDEO-BASED BIOMETRIC PERSON AUTHENTICATION,1206,345-352</dc:identifier><dc:identifier>3-540-62660-3</dc:identifier><dc:identifier>0302-9743</dc:identifier><dc:identifier>http://dspace.library.iitb.ac.in/xmlui/handle/10054/15123</dc:identifier><dc:identifier>http://hdl.handle.net/100/1878</dc:identifier><dc:source>1st International Conference on Audio-Based and Video-Based Biometric Person Authentication (AVBPA 97),CRANS MONTANA, SWITZERLAND,MAR 12-14, 1997</dc:source><dc:language>English</dc:language></oai_dc:dc>