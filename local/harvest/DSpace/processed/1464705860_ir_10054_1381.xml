<oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd"><identifier>ir-10054-1381</identifier><datestamp>2011-12-15T09:57:26Z</datestamp><dc:title>Accelerating Newton optimization for log-linear models through feature redundancy</dc:title><dc:creator>MATHUR, ARPIT</dc:creator><dc:creator>CHAKRABARTI, SOUMEN</dc:creator><dc:subject>newton-raphson method</dc:subject><dc:subject>feature extraction</dc:subject><dc:subject>mathematical models</dc:subject><dc:subject>vectors</dc:subject><dc:subject>redundancy</dc:subject><dc:subject>regression analysis</dc:subject><dc:description>Log-linear models are widely used for labeling feature vectors and graphical models, typically to estimate robust conditional distributions in presence of a large number of potentially redundant features. Limited-memory quasi-Newton methods like LBFGS or BLMVM are optimization workhorses for such applications, and most of the training time is spent computing the objective and gradient for the optimizer. We propose a simple technique to speed up the training optimization by clustering features dynamically, and interleaving the standard optimizer with another, coarse-grained, faster optimizer that uses far fewer variables. Experiments with logistic regression training for text classification and conditional random field (CRF) training for information extraction show promising speed-ups between 2× and 9× without any systematic or significant degradation in the quality of the estimated models.</dc:description><dc:publisher>IEEE</dc:publisher><dc:date>2009-05-19T02:49:53Z</dc:date><dc:date>2011-11-28T08:05:39Z</dc:date><dc:date>2011-12-15T09:57:26Z</dc:date><dc:date>2009-05-19T02:49:53Z</dc:date><dc:date>2011-11-28T08:05:39Z</dc:date><dc:date>2011-12-15T09:57:26Z</dc:date><dc:date>2006</dc:date><dc:type>Article</dc:type><dc:identifier>Proceedings of the Sixth International Conference on Data Mining, Hong Kong, China, 18-22 December 2006, 1-10</dc:identifier><dc:identifier>0-7695-2701-7</dc:identifier><dc:identifier>10.1109/ICDM.2006.11</dc:identifier><dc:identifier>http://hdl.handle.net/10054/1381</dc:identifier><dc:identifier>http://dspace.library.iitb.ac.in/xmlui/handle/10054/1381</dc:identifier><dc:language>en</dc:language></oai_dc:dc>