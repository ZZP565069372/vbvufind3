<oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd"><identifier>ir-10054-252</identifier><datestamp>2011-12-15T09:57:41Z</datestamp><dc:title>Use of Kohonen's self-organizing network as a pre-quantizer</dc:title><dc:creator>KHAPARDE, SA</dc:creator><dc:creator>GANDHI, HARISH</dc:creator><dc:subject>quantisation</dc:subject><dc:subject>self-organising feature maps</dc:subject><dc:description>Kohonen's network has the ability to achieve near optimal quantization of the input space. The Kohonen's training algorithm adapts very quickly to the input space and requires much less computation. Many experiments are carried out to compare the performance of the LBG algorithm and the Kohonen's algorithm. The variables used are the dimensionality of the input space and the level of organization. The results are found to confirm the faster adaptation of the Kohonen's algorithm although the final distortion levels are slightly higher. A combination of the two approaches is suggested to achieve lower distortion values with less training.</dc:description><dc:publisher>IEEE</dc:publisher><dc:date>2008-12-10T06:37:07Z</dc:date><dc:date>2011-11-28T08:31:14Z</dc:date><dc:date>2011-12-15T09:57:41Z</dc:date><dc:date>2008-12-10T06:37:07Z</dc:date><dc:date>2011-11-28T08:31:14Z</dc:date><dc:date>2011-12-15T09:57:41Z</dc:date><dc:date>1993</dc:date><dc:type>Article</dc:type><dc:identifier>Proceedings of the IEEE International Conference on Neural Networks (V 2), San Francisco, USA, 28 March -1 April, 1993, 967-971</dc:identifier><dc:identifier>0-7803-0999-5</dc:identifier><dc:identifier>10.1109/ICNN.1993.298688</dc:identifier><dc:identifier>http://hdl.handle.net/10054/252</dc:identifier><dc:identifier>http://dspace.library.iitb.ac.in/xmlui/handle/10054/252</dc:identifier><dc:language>en</dc:language></oai_dc:dc>