<oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd"><identifier>ir-100-14705</identifier><datestamp>2014-10-15T08:39:29Z</datestamp><dc:title>Multifocus and multispectral image fusion based on pixel significance using multiresolution decomposition</dc:title><dc:creator>SHAH, P</dc:creator><dc:creator>MERCHANT, SN</dc:creator><dc:creator>DESAI, UB</dc:creator><dc:subject>Image fusion</dc:subject><dc:subject>Multiresolution decomposition</dc:subject><dc:subject>Multifocus/Multispectral images</dc:subject><dc:subject>Context enhancement</dc:subject><dc:subject>WAVELET TRANSFORM</dc:subject><dc:subject>CONTOURLET TRANSFORM</dc:subject><dc:subject>PERFORMANCE</dc:subject><dc:subject>ALGORITHM</dc:subject><dc:subject>CURVELET</dc:subject><dc:description>Image fusion has been receiving increasing attention in the research community with the aim of investigating general formal solutions to a wide spectrum of applications. The objective of this work is to formulate a method that can efficiently fuse multifocus as well as multispectral images for context enhancement and thus can be used by different applications. We propose a novel pixel fusion rule based on multiresolution decomposition of the source images using wavelet, wavelet-packet, and contourlet transform. To compute fused pixel value, we take weighted average of the source pixels, where the weight to be given to the pixel is adaptively decided based on the significance of the pixel, which in turn is decided by the corresponding children pixels in the finer resolution bands. The fusion performance has been extensively tested on different types of images viz. multifocus images, medical images (CT and MRI), as well as IR - visible surveillance images. Several pairs of images were fused to compare the results quantitatively as well as qualitatively with various recently published methods. The analysis shows that for all the image types into consideration, the proposed method increases the quality of the fused image significantly, both visually and quantitatively, by preserving all the relevant information. The major achievement is average 50% reduction in artifacts.</dc:description><dc:publisher>SPRINGER LONDON LTD</dc:publisher><dc:date>2014-10-15T08:39:29Z</dc:date><dc:date>2014-10-15T08:39:29Z</dc:date><dc:date>2013</dc:date><dc:type>Article</dc:type><dc:identifier>SIGNAL IMAGE AND VIDEO PROCESSING, 7(1)95-109</dc:identifier><dc:identifier>http://dx.doi.org/10.1007/s11760-011-0219-7</dc:identifier><dc:identifier>http://dspace.library.iitb.ac.in/jspui/handle/100/14705</dc:identifier><dc:language>en</dc:language></oai_dc:dc>