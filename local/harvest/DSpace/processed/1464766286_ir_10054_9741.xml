<oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd"><identifier>ir-10054-9741</identifier><datestamp>2011-12-27T05:44:07Z</datestamp><dc:title>Determination of aircraft orientation for a vision-based system using artificial neural networks</dc:title><dc:creator>AGARWAL, S</dc:creator><dc:creator>CHAUDHURI, S</dc:creator><dc:subject>fourier descriptors</dc:subject><dc:subject>object recognition</dc:subject><dc:subject>moment invariants</dc:subject><dc:subject>image-analysis</dc:subject><dc:subject>aspect graphs</dc:subject><dc:subject>tracking</dc:subject><dc:subject>target</dc:subject><dc:subject>pose</dc:subject><dc:subject>3-d orientation estimation</dc:subject><dc:subject>pose estimation</dc:subject><dc:subject>moment invariants</dc:subject><dc:subject>principal axis moments</dc:subject><dc:subject>kohonen clustering</dc:subject><dc:subject>multi-layer perceptron</dc:subject><dc:description>An algorithm for real-time estimation of 3-D orientation of an aircraft, given its monocular, binary image from an arbitrary viewing direction is presented. This being an inverse problem, we attempt to provide an approximate but a fast solution using the artificial neural network technique. A set of spatial moments (scale, translation, and planar rotation invariant) is used as features to characterize different views of the aircraft, which corresponds to the feature space representation of the aircraft. A new neural network topology is suggested in order to solve the resulting functional approximation problem for the input (feature vector)-output (viewing direction) relationship. The feature space is partitioned into a number of subsets using a Kohonen clustering algorithm to express the complex relationship into a number of simpler ones. Separate multi-layer perceptrons (MLP) are then trained to capture the functional relations that exist between each class of feature vectors and the corresponding target orientation. This approach is shown to give better results when compared to those obtained with a single MLP trained for the entire feature space.</dc:description><dc:publisher>KLUWER ACADEMIC PUBL</dc:publisher><dc:date>2011-08-17T04:15:51Z</dc:date><dc:date>2011-12-26T12:55:20Z</dc:date><dc:date>2011-12-27T05:44:07Z</dc:date><dc:date>2011-08-17T04:15:51Z</dc:date><dc:date>2011-12-26T12:55:20Z</dc:date><dc:date>2011-12-27T05:44:07Z</dc:date><dc:date>1998</dc:date><dc:type>Article</dc:type><dc:identifier>JOURNAL OF MATHEMATICAL IMAGING AND VISION, 8(3), 255-269</dc:identifier><dc:identifier>0924-9907</dc:identifier><dc:identifier>http://dx.doi.org/10.1023/A:1008226702069</dc:identifier><dc:identifier>http://dspace.library.iitb.ac.in/xmlui/handle/10054/9741</dc:identifier><dc:identifier>http://hdl.handle.net/10054/9741</dc:identifier><dc:language>en</dc:language></oai_dc:dc>