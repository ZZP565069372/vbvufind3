<oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd"><identifier>ir-10054-1591</identifier><datestamp>2011-12-15T09:57:46Z</datestamp><dc:title>Search and transitioning for motion captured sequences</dc:title><dc:creator>BASU, SUDDHA</dc:creator><dc:creator>SHANBHAG, SHRINATH</dc:creator><dc:creator>SHARAT CHANDRAN</dc:creator><dc:subject>animation</dc:subject><dc:subject>data acquisition</dc:subject><dc:subject>database systems</dc:subject><dc:subject>information retrieval</dc:subject><dc:description>Animators today have started using motion captured (mocap) sequences to drive characters. Mocap allows rapid acquisition of highly realistic animation data. Consequently animators have at their disposal an enormous amount of mocap sequences which ironically has created a new retrieval problem. Thus, while working with mocap databases, an animator often needs to work with a subset of ``useful'' clips. Once the animator selects a candidate working set of motion clips, she then needs to identify appropriate transition points amongst these clips for maximal reuse.In this paper, we describe methods for querying mocap databases and identifying transitions for a given set of clips. We preprocess clips (and clip subsequences), and precompute frame locations to allow interactive stitching. In contrast with existing methods that view each individual clips as nodes, for optimal reuse, we reduce the granularity.</dc:description><dc:publisher>Association for Computing Machinery</dc:publisher><dc:date>2009-07-04T05:59:24Z</dc:date><dc:date>2011-11-28T08:43:46Z</dc:date><dc:date>2011-12-15T09:57:45Z</dc:date><dc:date>2009-07-04T05:59:24Z</dc:date><dc:date>2011-11-28T08:43:46Z</dc:date><dc:date>2011-12-15T09:57:45Z</dc:date><dc:date>2005</dc:date><dc:identifier>Proceedings of the ACM Symposium on Virtual Reality Software and Technology, (VRST), Monterey, CA, USA, 7-9 November 2005, 220-223</dc:identifier><dc:identifier>1-59593-098-1</dc:identifier><dc:identifier>10.1145/1101616.1101660</dc:identifier><dc:identifier>http://hdl.handle.net/10054/1591</dc:identifier><dc:identifier>http://dspace.library.iitb.ac.in/xmlui/handle/10054/1591</dc:identifier><dc:language>en</dc:language></oai_dc:dc>