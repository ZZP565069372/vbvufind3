<oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd"><identifier>ir-10054-10099</identifier><datestamp>2011-12-27T05:43:03Z</datestamp><dc:title>Collective Inference for Extraction MRFs Coupled with Symmetric Clique Potentials</dc:title><dc:creator>GUPTA, R</dc:creator><dc:creator>SARAWAGI, S</dc:creator><dc:creator>DIWAN, AA</dc:creator><dc:subject>graph cuts</dc:subject><dc:subject>energy minimization</dc:subject><dc:subject>classification</dc:subject><dc:subject>algorithms</dc:subject><dc:subject>graphical models</dc:subject><dc:subject>collective inference</dc:subject><dc:subject>clique potentials</dc:subject><dc:subject>cluster graphs</dc:subject><dc:subject>message passing</dc:subject><dc:description>Many structured information extraction tasks employ collective graphical models that capture inter-instance associativity by coupling them with various clique potentials. We propose tractable families of such potentials that are invariant under permutations of their arguments, and call them symmetric clique potentials. We present three families of symmetric potentials-MAX, SUM, and MAJORITY. We propose cluster message passing for collective inference with symmetric clique potentials, and present message computation algorithms tailored to such potentials. Our first message computation algorithm, called alpha-pass, is sub-quadratic in the clique size, outputs exact messages for MAX, and computes 13/15-approximate messages for Potts, a popular member of the SUM family. Empirically, it is upto two orders of magnitude faster than existing algorithms based on graph-cuts or belief propagation. Our second algorithm, based on Lagrangian relaxation, operates on MAJORITY potentials and provides close to exact solutions while being two orders of magnitude faster. We show that the cluster message passing framework is more principled, accurate and converges faster than competing approaches. We extend our collective inference framework to exploit associativity of more general intra-domain properties of instance labelings, which opens up interesting applications in domain adaptation. Our approach leads to significant error reduction on unseen domains without incurring any overhead of model retraining.</dc:description><dc:publisher>MICROTOME PUBL</dc:publisher><dc:date>2011-08-18T18:20:24Z</dc:date><dc:date>2011-12-26T12:55:52Z</dc:date><dc:date>2011-12-27T05:43:03Z</dc:date><dc:date>2011-08-18T18:20:24Z</dc:date><dc:date>2011-12-26T12:55:52Z</dc:date><dc:date>2011-12-27T05:43:03Z</dc:date><dc:date>2010</dc:date><dc:type>Article</dc:type><dc:identifier>JOURNAL OF MACHINE LEARNING RESEARCH, 11(), 3097-3135</dc:identifier><dc:identifier>1532-4435</dc:identifier><dc:identifier>http://dspace.library.iitb.ac.in/xmlui/handle/10054/10099</dc:identifier><dc:identifier>http://hdl.handle.net/10054/10099</dc:identifier><dc:language>en</dc:language></oai_dc:dc>