<oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd"><identifier>ir-10054-8525</identifier><datestamp>2013-11-08T10:19:35Z</datestamp><dc:title>Vocal Melody Extraction in the Presence of Pitched Accompaniment in Polyphonic Music</dc:title><dc:creator>RAO, V</dc:creator><dc:creator>RAO, P</dc:creator><dc:subject>fundamental-frequency estimation</dc:subject><dc:subject>singing voice</dc:subject><dc:subject>source separation</dc:subject><dc:subject>monaural recordings</dc:subject><dc:subject>multipitch analysis</dc:subject><dc:subject>signals</dc:subject><dc:subject>speech</dc:subject><dc:subject>audio</dc:subject><dc:subject>algorithm</dc:subject><dc:subject>tracking</dc:subject><dc:subject>fundamental frequency estimation</dc:subject><dc:subject>music information retrieval (mir)</dc:subject><dc:subject>music transcription</dc:subject><dc:subject>predominant pitch detection</dc:subject><dc:description>Melody extraction algorithms for single-channel polyphonic music typically rely on the salience of the lead melodic instrument, considered here to be the singing voice. However the simultaneous presence of one or more pitched instruments in the polyphony can cause such a predominant-F0 tracker to switch between tracking the pitch of the voice and that of an instrument of comparable strength, resulting in reduced voice-pitch detection accuracy. We propose a system that, in addition to biasing the salience measure in favor of singing voice characteristics, acknowledges that the voice may not dominate the polyphony at all instants and therefore tracks an additional pitch to better deal with the potential presence of locally dominant pitched accompaniment. A feature based on the temporal instability of voice harmonics is used to finally identify the voice pitch. The proposed system is evaluated on test data that is representative of polyphonic music with strong pitched accompaniment. Results show that the proposed system is indeed able to recover melodic information lost to its single-pitch tracking counterpart, and also outperforms another state-of-the-art melody extraction system designed for polyphonic music.</dc:description><dc:publisher>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</dc:publisher><dc:date>2011-08-01T19:35:58Z</dc:date><dc:date>2011-12-26T12:53:28Z</dc:date><dc:date>2011-12-27T05:39:31Z</dc:date><dc:date>2011-08-01T19:35:58Z</dc:date><dc:date>2011-12-26T12:53:28Z</dc:date><dc:date>2011-12-27T05:39:31Z</dc:date><dc:date>2010</dc:date><dc:type>Article</dc:type><dc:identifier>IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING, 18(8), 2145-2154</dc:identifier><dc:identifier>1558-7916</dc:identifier><dc:identifier>http://dx.doi.org/10.1109/TASL.2010.2042124</dc:identifier><dc:identifier>http://dspace.library.iitb.ac.in/xmlui/handle/10054/8525</dc:identifier><dc:identifier>http://hdl.handle.net/10054/8525</dc:identifier><dc:language>en</dc:language></oai_dc:dc>