<oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd"><identifier>ir-100-2403</identifier><datestamp>2011-12-15T09:11:58Z</datestamp><dc:title>Multilingual PRF : English lends a helping hand</dc:title><dc:creator>CHINNAKOTLA, MK</dc:creator><dc:creator>RAMAN, K</dc:creator><dc:creator>BHATTACHARYYA, P</dc:creator><dc:subject>information-retrieval</dc:subject><dc:subject>models</dc:subject><dc:subject>multilingual</dc:subject><dc:subject>pseudo-relevance feedback</dc:subject><dc:subject>language models</dc:subject><dc:subject>query expansion</dc:subject><dc:description>In this paper, we present a novel approach to Pseudo-Relevance Feedback (PRF) called Multilingual PRF (MultiPRF). The key idea is to harness multilinguality. Given a query in a language, we take the help of another language to ameliorate the well known problems of PRF, viz. (a) The expansion terms from PRF are primarily based on co-occurrence relationships with query terms, and thus other terms which are lexically and semantically related, such as morphological variants and synonyms, are not explicitly captured, and (b) PRF is quite sensitive to the quality of the initially retrieved top k documents and is thus not robust. In MultiPRF, given a query in language L(1), it is translated into language L(2) and PRF is performed on a collection in language L(2) and the resultant feedback model is translated from L(2) back into L(1). The final feedback model is obtained by combining the translated model with the original feedback model of the query in L(1). Experiments were performed on standard CLEF collections in languages with widely differing characteristics, viz., French, German, Finnish and Hungarian with English as the assisting language. We observe that MultiPRF outperforms PRF and is more robust with consistent and significant improvements in the above widely differing languages. A thorough analysis of the results reveal that the second language helps in obtaining both co-occurrence based conceptual terms as well as lexically and semantically related terms. Additionally, the use of the second language collection reduces the sensitivity to performance of initial retrieval, thereby making it more robust.</dc:description><dc:publisher>ASSOC COMPUTING MACHINERY</dc:publisher><dc:date>2011-10-25T14:33:07Z</dc:date><dc:date>2011-12-15T09:11:58Z</dc:date><dc:date>2011-10-25T14:33:07Z</dc:date><dc:date>2011-12-15T09:11:58Z</dc:date><dc:date>2010</dc:date><dc:type>Proceedings Paper</dc:type><dc:identifier>SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL,659-666</dc:identifier><dc:identifier>978-1-60558-896-4</dc:identifier><dc:identifier>http://dspace.library.iitb.ac.in/xmlui/handle/10054/15746</dc:identifier><dc:identifier>http://hdl.handle.net/100/2403</dc:identifier><dc:source>33rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,Geneva, SWITZERLAND,JUL 19-23, 2010</dc:source><dc:language>English</dc:language></oai_dc:dc>